{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combffq = pd.read_stata('../Combffq_04Apr19.dta')\n",
    "Combpaq = pd.read_stata('../Combpaq_04Apr19.dta')\n",
    "PEvent = pd.read_stata('../PEvent_04Apr19.dta')\n",
    "nutrition_vars = pd.read_table('nutritionVariables.txt', sep=',')\n",
    "physical_activities = pd.read_table('physicalActivities.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffqcols = ['idno'] + list(nutrition_vars.abbreviation)\n",
    "paqcols = ['idno'] + [_.lower() for _ in physical_activities.abbreviation]\n",
    "merged_data = Combffq[ffqcols].merge(Combpaq[paqcols], left_on='idno', right_on='idno', how='inner')\n",
    "merged_data = merged_data.merge(PEvent[['idno', 'newdiab']], left_on='idno', right_on='idno', how='inner')\n",
    "# null_series = merged_data.isna().sum().sort_values(ascending=False)\n",
    "# too_null_cols = null_series[(null_series>5000)]\n",
    "# DF = merged_data.drop(too_null_cols.index.tolist(), axis=1)\n",
    "DF = merged_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_train, X_test, y_all_train, y_test = train_test_split(DF.iloc[:,1:-1], DF.iloc[:,-1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetic_idx = np.ndarray.flatten(np.array(np.where(y_all_train==1)))\n",
    "# upsampling_idx = np.random.choice(diabetic_idx, len(y_all_train)-2*len(diabetic_idx), replace=True)\n",
    "# sampled_X = pd.concat([X_all_train, X_all_train.iloc[upsampling_idx,]])\n",
    "# sampled_y = pd.concat([y_all_train, y_all_train.iloc[upsampling_idx,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_idx = np.ndarray.flatten(np.array(np.where(y_all_train==0)))\n",
    "diabetic_idx = np.ndarray.flatten(np.array(np.where(y_all_train==1)))\n",
    "downsample_len = int(len(diabetic_idx)/2)\n",
    "downsampling_idx = np.concatenate((np.random.choice(healthy_idx, downsample_len),np.random.choice(diabetic_idx, downsample_len)), axis=None)\n",
    "np.random.shuffle(downsampling_idx)\n",
    "sampled_X = X_all_train.iloc[downsampling_idx,]\n",
    "sampled_y = y_all_train.iloc[downsampling_idx,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You may verify the effect of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsampled_X = X_all_train\n",
    "unsampled_y = y_all_train\n",
    "# sampled_X = unsampled_X\n",
    "# sampled_y = unsampled_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-Normalization only based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_cols = ['wtredr', 'psfat']\n",
    "# percentage_cols = ['pertotfat', 'persatfat', 'perprotein' ,'percho' ,'permufa' ,'perpufa']\n",
    "# value_cols = list(set(sampled_X.columns)-set(ratio_cols)-set(percentage_cols))\n",
    "# train_mean = sampled_X[value_cols].mean()\n",
    "# train_std = sampled_X[value_cols].std()\n",
    "# sampled_X.loc[:,percentage_cols] = sampled_X.loc[:,percentage_cols]/100\n",
    "# X_test.loc[:,percentage_cols] = X_test.loc[:,percentage_cols]/100\n",
    "# sampled_X.loc[:,value_cols] = (sampled_X.loc[:,value_cols] - train_mean)/train_std\n",
    "# X_test.loc[:,value_cols] = (X_test.loc[:,value_cols] - train_mean)/train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Scaling only based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cols = ['wtredr', 'psfat']\n",
    "percentage_cols = ['pertotfat', 'persatfat', 'perprotein' ,'percho' ,'permufa' ,'perpufa']\n",
    "value_cols = list(set(sampled_X.columns)-set(ratio_cols)-set(percentage_cols))\n",
    "train_max = sampled_X.loc[:,value_cols].max()\n",
    "train_min = sampled_X.loc[:,value_cols].min()\n",
    "sampled_X.loc[:,percentage_cols] = sampled_X.loc[:,percentage_cols]/100\n",
    "X_test.loc[:,percentage_cols] = X_test.loc[:,percentage_cols]/100\n",
    "sampled_X.loc[:,value_cols] = (sampled_X.loc[:,value_cols] - train_min)/(train_max-train_min)\n",
    "X_test.loc[:,value_cols] = (X_test.loc[:,value_cols] - train_min)/(train_max-train_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train into train and validation for the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(sampled_X, sampled_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forest(blen, bcount, X_train, y_train):\n",
    "    all_idx = range(len(X_train))\n",
    "    batch_idx = [np.random.choice(all_idx, blen, replace=True) for _ in range(bcount)]\n",
    "    model = RandomForestClassifier(warm_start=True, n_estimators=1)\n",
    "    for b in batch_idx:\n",
    "        X_batch = X_train.iloc[b,]\n",
    "        y_batch = y_train.iloc[b,]\n",
    "        model.fit(X_batch, y_batch)\n",
    "        model.n_estimators = model.n_estimators + 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc, best_len, best_count = [0, 2000, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 100 batches, each with size equal to  1000 :\n",
      "\t area under the curve:  0.5\n",
      "testing 300 batches, each with size equal to  1000 :\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-150013f2502d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_counts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"testing\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"batches, each with size equal to \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t area under the curve: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-292156387981>\u001b[0m in \u001b[0;36mbuild_forest\u001b[1;34m(blen, bcount, X_train, y_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mall_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbatch_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-292156387981>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mall_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbatch_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_lens = range(1000,2300, 300)\n",
    "batch_counts = [100, 300, 500, 700]\n",
    "for l in  batch_lens:\n",
    "#     print(\"testing batches with size equal to \", l)\n",
    "    for c in batch_counts:\n",
    "        print(\"testing\", str(c), \"batches, each with size equal to \", str(l), \":\")\n",
    "        model = build_forest(l, c, X_train, y_train)\n",
    "        res = evaluate(model, X_val, y_val)\n",
    "        print(\"\\t area under the curve: \", str(res))\n",
    "        if res > best_auc:\n",
    "            best_auc = res\n",
    "            best_len = l\n",
    "            best_count = c\n",
    "#     print(\"best auc so far: \", best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_forest(best_len, best_count, sampled_X, sampled_y)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_auc, best_count, best_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_forest(best_len, best_count, X_train, y_train)\n",
    "# y_pred = model.predict(X_val)\n",
    "# print(confusion_matrix(y_val, y_pred))\n",
    "# print(classification_report(y_val, y_pred))\n",
    "# print(roc_auc_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28057     8]\n",
      " [ 1084     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     28065\n",
      "         1.0       0.00      0.00      0.00      1084\n",
      "\n",
      "    accuracy                           0.96     29149\n",
      "   macro avg       0.48      0.50      0.49     29149\n",
      "weighted avg       0.93      0.96      0.94     29149\n",
      "\n",
      "0.49985747372171746\n"
     ]
    }
   ],
   "source": [
    "rfClassifier = RandomForestClassifier()\n",
    "rfClassifier.fit(sampled_X, sampled_y)\n",
    "rf_y_pred = rfClassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, rf_y_pred))\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "print(roc_auc_score(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should do it on the correct splits! \n",
    "rfClassifier = RandomForestClassifier()\n",
    "rfClassifier.fit(X_train, y_train)\n",
    "rf_y_pred = rfClassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, rf_y_pred))\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "print(roc_auc_score(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=2)\n",
    "knnClassifier.fit(sampled_X, sampled_y)\n",
    "knn_y_pred = knnClassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, knn_y_pred))\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "print(roc_auc_score(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtClassifier = DecisionTreeClassifier()\n",
    "dtClassifier.fit(sampled_X, sampled_y)\n",
    "dt_y_pred = dtClassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, dt_y_pred))\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "print(roc_auc_score(y_test, dt_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_pred = np.zeros(len(rf_y_pred))\n",
    "for i in range(len(rf_y_pred)):\n",
    "    if rf_y_pred[i]+knn_y_pred[i]+dt_y_pred[i] >= 2:\n",
    "        voting_pred[i] = 1\n",
    "print(confusion_matrix(y_test, voting_pred))\n",
    "print(classification_report(y_test, voting_pred))\n",
    "print(roc_auc_score(y_test, voting_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = DF.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "g=sns.heatmap(DF[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "plt.savefig('corr.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(model)\n",
    "sel.fit(sampled_X, sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_X.columns[(sel.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.series(sel.estimator_,feature_importances_,.ravel()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ffqcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paqcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_data.columns), len(DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-pure_diabetes] *",
   "language": "python",
   "name": "conda-env-conda-pure_diabetes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
