{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# A good example for data science pipeline\n",
    "# https://courses.cs.ut.ee/MTAT.03.227/2019_fall/uploads/Main/python_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/dhi_work/students/chenj4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_allcountry_ahei_AllVars_2019-01-16.xlsx\r\n",
      "Baseline_allcountry_ahei_AllVars_2019-01-16.xlsx.csv\r\n",
      "Baseline_combpaq_AllVars_2019-01-16.xlsx\r\n",
      "Baseline_combpaq_AllVars_2019-01-16.xlsx.csv\r\n",
      "Baseline_morevarspureadult_AllVars_2019-01-16.xlsx\r\n",
      "Baseline_morevarspureadult_AllVars_2019-01-16.xlsx.csv\r\n",
      "PURE_diabetes\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"/dhi_work/students/chenj4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 400\r\n",
      "drwx------ 3 chenj4  studies   4096 Mar 20 17:27 .\r\n",
      "drwxr-xr-x 4 nelsonw studies   4096 Mar  9 20:32 ..\r\n",
      "-rw-r--r-- 1 chenj4  studies  16847 Mar 20 17:27 Baseline_allcountry_ahei_AllVars_2019-01-16.xlsx\r\n",
      "-rw-r--r-- 1 chenj4  studies  11766 Mar 20 17:25 Baseline_allcountry_ahei_AllVars_2019-01-16.xlsx.csv\r\n",
      "-rw-r--r-- 1 chenj4  studies  22816 Mar 20 17:27 Baseline_combpaq_AllVars_2019-01-16.xlsx\r\n",
      "-rw-r--r-- 1 chenj4  studies  21485 Mar 20 17:25 Baseline_combpaq_AllVars_2019-01-16.xlsx.csv\r\n",
      "-rw-r--r-- 1 chenj4  studies 130622 Mar 20 17:27 Baseline_morevarspureadult_AllVars_2019-01-16.xlsx\r\n",
      "-rw-r--r-- 1 chenj4  studies 166112 Mar 20 17:25 Baseline_morevarspureadult_AllVars_2019-01-16.xlsx.csv\r\n",
      "drwx------ 2 chenj4  studies   4096 Mar  9 20:26 PURE_diabetes\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al \"/dhi_work/students/chenj4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    }
   ],
   "source": [
    "print(\"HELLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1052208\r\n",
      "drwx------ 2 chenj4 studies      4096 Mar  9 20:26 .\r\n",
      "drwx------ 3 chenj4 studies      4096 Mar 20 17:27 ..\r\n",
      "-rwx------ 1 chenj4 studies 211030727 Mar  9 20:26 Combffq_04Apr19.dta\r\n",
      "-rwx------ 1 chenj4 studies 397679602 Mar  9 20:26 Combpaq_04Apr19.dta\r\n",
      "-rwx------ 1 chenj4 studies     24763 Mar  9 20:26 PAQ_Derived_2018-05-31.xlsx\r\n",
      "-rwx------ 1 chenj4 studies 223129693 Mar  9 20:26 PBline_04Apr19.dta\r\n",
      "-rwx------ 1 chenj4 studies  20926356 Mar  9 20:26 PEvent_04Apr19.dta\r\n",
      "-rwx------ 1 chenj4 studies 220367908 Mar  9 20:26 PFollow_04Apr19.dta\r\n",
      "-rwx------ 1 chenj4 studies     24612 Mar  9 20:26 ahei_derived_2018-05-31.xlsx\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al \"/dhi_work/students/chenj4/PURE_diabetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/dhi_work/students/chenj4/PURE_diabetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combffq = pd.read_stata(os.path.join(PATH, 'Combffq_04Apr19.dta'))\n",
    "Combpaq = pd.read_stata(os.path.join(PATH, 'Combpaq_04Apr19.dta'))\n",
    "PBline = pd.read_stata(os.path.join(PATH, 'PBline_04Apr19.dta'))\n",
    "PEvent = pd.read_stata(os.path.join(PATH, 'PEvent_04Apr19.dta'))\n",
    "PFollow = pd.read_stata(os.path.join(PATH, 'PFollow_04Apr19.dta')) #according to Shuang, we should not use PFollow since it is spurious (the golden goose of all Kaggle comps!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paq_internalguid      192098\n",
       "subjectkey            192098\n",
       "countryname           192098\n",
       "localcode             192098\n",
       "subinpaq              192098\n",
       "datepaq               146968\n",
       "poccup                192098\n",
       "paqfi                 192098\n",
       "paqln                 192098\n",
       "pintcode              192098\n",
       "applicationversion    192098\n",
       "lastmodifiedby        192098\n",
       "createddate           192098\n",
       "lastmodifieddate      192098\n",
       "iso3digitcountry      150239\n",
       "centid                192098\n",
       "commid                179313\n",
       "housid                179313\n",
       "subjid                179313\n",
       "pcjob                 190586\n",
       "pchday                 96356\n",
       "pchhrs                100624\n",
       "pchmin                 99953\n",
       "pchno                 170800\n",
       "pcmday                104223\n",
       "pcmhrs                108455\n",
       "pcmmin                106685\n",
       "pcmno                 170777\n",
       "pcwday                 98447\n",
       "pcwhrs                101819\n",
       "                       ...  \n",
       "job_all               192098\n",
       "trans_all             192098\n",
       "house_all             192098\n",
       "recrt_all             192098\n",
       "sitminswkday          168741\n",
       "sitminswkend          159038\n",
       "metsit                190689\n",
       "metsitweekday         168741\n",
       "metsitweekend         159038\n",
       "totsitall             187098\n",
       "avgsitall             187098\n",
       "metrecrt525           182843\n",
       "totwalkmet            178159\n",
       "totmodmet             182882\n",
       "totvigmet             182611\n",
       "physactivall          168441\n",
       "physact               185669\n",
       "metguide              185669\n",
       "studyid               192098\n",
       "allminswk              17426\n",
       "totwalkwk              17404\n",
       "totmodwk               17404\n",
       "totvigwk               17404\n",
       "minwk1                 17404\n",
       "physact_who            17404\n",
       "key_country           191691\n",
       "key_incctry           191691\n",
       "key_centid            191691\n",
       "key_commid            191691\n",
       "key_hhid              191691\n",
       "Length: 189, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combffq has a lot of nutrition data\n",
    "# and there is richness derived data as well!\n",
    "Combpaq.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allminsday\n",
      "allminswk\n",
      "applicationversion\n",
      "avgsitall\n",
      "biketransmet\n",
      "centid\n",
      "cescas_id\n",
      "commid\n",
      "communityid\n",
      "country\n",
      "countryname\n",
      "createddate\n",
      "ctry\n",
      "ctryp\n",
      "datepaq\n",
      "datepaqdd\n",
      "datepaqmm\n",
      "datepaqyyyy\n",
      "epochid\n",
      "gdpctry\n",
      "gdpctryr\n",
      "hhid\n",
      "house_all\n",
      "housid\n",
      "idno\n",
      "incctry\n",
      "incctryn\n",
      "incctrynn\n",
      "iso3digitcountry\n",
      "job_all\n",
      "key_centid\n",
      "key_commid\n",
      "key_country\n",
      "key_hhid\n",
      "key_incctry\n",
      "lastmodifiedby\n",
      "lastmodifieddate\n",
      "leisactv1\n",
      "leisactv2\n",
      "leisactv3\n",
      "leisphysact\n",
      "localcode\n",
      "location\n",
      "metall\n",
      "metguide\n",
      "methouse\n",
      "metjob\n",
      "metrecrt\n",
      "metrecrt525\n",
      "metsit\n",
      "metsitweekday\n",
      "metsitweekend\n",
      "mettrans\n",
      "minwk1\n",
      "modhousinmet\n",
      "modhousoutmet\n",
      "modrecmet\n",
      "modworkmet\n",
      "new_centid\n",
      "new_country\n",
      "paq_internalguid\n",
      "paqfi\n",
      "paqln\n",
      "pchday\n",
      "pchhrs\n",
      "pchmin\n",
      "pchminsday\n",
      "pchminswk\n",
      "pchno\n",
      "pchweek\n",
      "pcjob\n",
      "pcmday\n",
      "pcmhrs\n",
      "pcmmin\n",
      "pcmminsday\n",
      "pcmminswk\n",
      "pcmno\n",
      "pcmweek\n",
      "pcwday\n",
      "pcwhrs\n",
      "pcwmin\n",
      "pcwminsday\n",
      "pcwminswk\n",
      "pcwno\n",
      "pcwweek\n",
      "peru_id\n",
      "phase\n",
      "phmday\n",
      "phmhrs\n",
      "phmmin\n",
      "phmminsday\n",
      "phmminswk\n",
      "phmno\n",
      "phmpday\n",
      "phmphrs\n",
      "phmpmin\n",
      "phmpminsday\n",
      "phmpminswk\n",
      "phmpno\n",
      "phmpweek\n",
      "phmweek\n",
      "phvday\n",
      "phvhrs\n",
      "phvmin\n",
      "phvminsday\n",
      "phvminswk\n",
      "phvno\n",
      "phvweek\n",
      "physact\n",
      "physact_who\n",
      "physactivall\n",
      "pintcode\n",
      "poccup\n",
      "pons_id\n",
      "prsmday\n",
      "prsmhrs\n",
      "prsmmin\n",
      "prsmminsday\n",
      "prsmminswk\n",
      "prsmno\n",
      "prsmweek\n",
      "prsvday\n",
      "prsvhrs\n",
      "prsvmin\n",
      "prsvminsday\n",
      "prsvminswk\n",
      "prsvno\n",
      "prsvweek\n",
      "prswday\n",
      "prswhrs\n",
      "prswmin\n",
      "prswminsday\n",
      "prswminswk\n",
      "prswno\n",
      "prswweek\n",
      "ptbday\n",
      "ptbhrs\n",
      "ptbmin\n",
      "ptbminsday\n",
      "ptbminswk\n",
      "ptbno\n",
      "ptbweek\n",
      "ptmday\n",
      "ptmhrs\n",
      "ptmmin\n",
      "ptmminsday\n",
      "ptmminswk\n",
      "ptmno\n",
      "ptmweek\n",
      "ptssdhrs\n",
      "ptssdmin\n",
      "ptsshrs\n",
      "ptssmin\n",
      "ptwday\n",
      "ptwhrs\n",
      "ptwmin\n",
      "ptwminsday\n",
      "ptwminswk\n",
      "ptwno\n",
      "ptwweek\n",
      "recrt_all\n",
      "region\n",
      "region2\n",
      "region2a\n",
      "regionn\n",
      "sitminswkday\n",
      "sitminswkend\n",
      "studyid\n",
      "subinpaq\n",
      "subjectkey\n",
      "subjid\n",
      "totmodday\n",
      "totmodmet\n",
      "totmodwk\n",
      "totsitall\n",
      "totvigday\n",
      "totvigmet\n",
      "totvigwk\n",
      "totwalkday\n",
      "totwalkmet\n",
      "totwalkwk\n",
      "trans_all\n",
      "version\n",
      "vighousmet\n",
      "vigrecmet\n",
      "vigworkmet\n",
      "walkrecmet\n",
      "walktransmet\n",
      "walkworkmet\n"
     ]
    }
   ],
   "source": [
    "for column in sorted(Combpaq.columns):\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idno           155147\n",
       "dairy          151439\n",
       "fruits         151438\n",
       "vegets         151439\n",
       "meats          151439\n",
       "redmeat        151439\n",
       "wtmeat         151439\n",
       "fish           151439\n",
       "starch         151439\n",
       "sfdrink        149502\n",
       "alcohol        119611\n",
       "saltfood       147735\n",
       "procfood       149781\n",
       "transfat       151439\n",
       "nuts           138540\n",
       "dairy_g        155147\n",
       "fruits_g       155146\n",
       "vegets_g       155147\n",
       "meats_g        155147\n",
       "redmeat_g      155147\n",
       "wtmeat_g       155147\n",
       "fish_g         155147\n",
       "starch_g       155147\n",
       "sfdrink_g      153210\n",
       "alcohol_g      123319\n",
       "saltfood_g     151443\n",
       "procfood_g     153489\n",
       "transfat_g     155147\n",
       "nuts_g         142248\n",
       "fibcereal      146714\n",
       "                ...  \n",
       "lycopene       101890\n",
       "lutzea         101890\n",
       "vit_e          150418\n",
       "vit_k          103761\n",
       "fa_sat         155147\n",
       "fa_mono        155147\n",
       "fa_poly        155147\n",
       "cholestrl      152200\n",
       "wtredr         155147\n",
       "psfat          155147\n",
       "pertotfat      155147\n",
       "persatfat      155147\n",
       "perprotein     155147\n",
       "percho         155147\n",
       "permufa        155147\n",
       "perpufa        155147\n",
       "vegs           155147\n",
       "fruitsc        155147\n",
       "nutsc          155147\n",
       "wtredrs        155147\n",
       "fibs           155147\n",
       "psfats         155147\n",
       "frys           155147\n",
       "aheiscore      155147\n",
       "epochid        155147\n",
       "key_country    155147\n",
       "key_incctry    155147\n",
       "key_centid     155147\n",
       "key_commid     155147\n",
       "key_hhid       155147\n",
       "Length: 170, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combffq.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combffq[\"idno\"].intersect(PEvent[\"idno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idno           163466\n",
       "subjid           3795\n",
       "aid            163466\n",
       "newdiab        163466\n",
       "newmi          163466\n",
       "newstrk        163466\n",
       "newhf          163466\n",
       "cvd            163466\n",
       "severecvd      163466\n",
       "fday_mi        161820\n",
       "fday_strk      161820\n",
       "fday_hf        161820\n",
       "fday_cvd       161313\n",
       "fday_sevcvd    161818\n",
       "fday_dm        161821\n",
       "fup            163466\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PEvent.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try joining!\n",
    "merged_data = PEvent.merge(Combffq,how=\"inner\", on=\"idno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.merge(Combpaq, how=\"inner\", on=\"idno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data = merged_data.merge(PFollow, how=\"inner\", on=\"idno\")\n",
    "merged_data = merged_data.merge(PBline, how=\"inner\", on=\"idno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Combffq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in sorted(Combpaq.columns):\n",
    "#     print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEvent[PEvent[\"newdiab\"] == 1][\"newdiab\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEvent[PEvent[\"newdiab\"] == 0][\"newdiab\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEvent[PEvent[\"newdiab\"] == 1][\"newdiab\"].count()/PEvent[\"newdiab\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data[\"incCtryN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in sorted(merged_data.columns):\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''Income related variables'''\n",
    "incctry_x\n",
    "incctry_y\n",
    "incctryn\n",
    "incctrynn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[[\"incctry_x\", \"incctry_y\", \"incctryn\", \"incctrynn\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataset for scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_series = merged_data.isna().sum().sort_values(ascending=False) # we should drop the subjid too! (unless we use it with something else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_series[\"fish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_series[\"incctryn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of columns where null series has more than 5000 null entries\n",
    "\n",
    "too_null_cols = null_series[(null_series>5000)] # there are 83 columns where there are more than 5k null entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we just need to NOT pick these columns\n",
    "too_null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(too_null_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(too_null_cols.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data = merged_data.drop(too_null_cols.index.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in sorted(non_null_merged_data.columns):\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data[\"incctryn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data = non_null_merged_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_merged_data = non_null_merged_data.loc[non_null_merged_data[\"incctryn\" ]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = non_null_merged_data.drop(columns=[\"idno\", \"newdiab\"])\n",
    "y_all = non_null_merged_data[\"newdiab\"] # we should be able to index back in (assuming we kept the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sorted(X_all.columns):\n",
    "    print(col, X_all[col].dtype)\n",
    "    \n",
    "#     we could drop all the cateogires. If we have category, then we can also do a look up. That is, \n",
    "# we can try some sort of conversion from category to one hot categorical vector. But we need some sort of \n",
    "# transformer that does that! \n",
    "# ALSO, recall the data science spark datacamp tutorial! \n",
    "# that one was roughly pretty good\n",
    "# Recall, we had info on how we can do various transformation methods, such as string binarization etc.\n",
    "\n",
    "'''\n",
    "The overall pipeline is as follows: \n",
    "1. We will have some EDA\n",
    "\n",
    "df = pd.read_csv() etc.\n",
    "\n",
    "2. We will then massage the data into the format necessary for the sklearn algo: \n",
    "3. model should be built, and then accepts the dataframe\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns with category. \n",
    "# X_all.categorical\n",
    "# to_be_dropped=pd.DataFrame(X_all.categorical).columns\n",
    "X_all= X_all.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into rich, middle and poor income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we import the sci-kit learn and do everything for prediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaclassifier = AdaBoostClassifier()\n",
    "adaclassifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_y_pred = adaclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, ada_y_pred))\n",
    "print(classification_report(y_test, ada_y_pred))\n",
    "print(roc_auc_score(y_test, ada_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature_indices = sorted(range(len(adaclassifier.feature_importances_)), key=lambda i: adaclassifier.feature_importances_[i])[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaclassifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:,top_feature_indices].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # a couple things: we want to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_pred = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "print(confusion_matrix(y_test, knn_y_pred))\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "print(roc_auc_score(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier()\n",
    "rfclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_y_pred = rfclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, rf_y_pred))\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "print(roc_auc_score(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "hidden_layer_sizes=(512, 256), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "nn_y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, nn_y_pred))\n",
    "print(classification_report(y_test, nn_y_pred))\n",
    "print(roc_auc_score(y_test, nn_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "# #Create a svm Classifier\n",
    "# clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "# svm_y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test, svm_y_pred))\n",
    "# print(classification_report(y_test, svm_y_pred))\n",
    "# print(roc_auc_score(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combpaq.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEvent.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEvent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFollow.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nutrition_vars = pd.read_table('nutritionVariables.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['idno'] + list(nutrition_vars.abbreviation)\n",
    "DF = Combffq[cols].merge(PEvent[['idno', 'newdiab']], left_on='idno', right_on='idno', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
